{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST is a drop-in replacement for the very well known, machine learning hello world, MNIST dataset. It has same number of training and test examples and the images have the same 28x28 size and there are a total of 10 classes/labels, you can read more about the dataset here : [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "\n",
    "\n",
    "## Approach\n",
    "\n",
    "VGG Like Model With Batchnorm\n",
    "\n",
    "Split the original training data into 80% training and 20% validation. This helps to see weather we're over-fitting on the training data and weather we should lower the learning rate and train for more epochs if validation accuracy is higher than training accuracy or stop over-training if training accuracy shift higher than the validation.\n",
    "\n",
    "The model is initially trained for 10 epochs and another 10 epochs with a lower learning late. After the initial 20 epochs, data augmentation is added, which generates new training samples by rotating, shifting and zooming on the training samples, and trained for another 50 epochs.\n",
    "\n",
    "Also, to avoid hot encoding the labels, `sparse_categorical_crossentropy` is used when compiling the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Ubuntu\"\r\n",
      "VERSION=\"14.04.5 LTS, Trusty Tahr\"\r\n",
      "ID=ubuntu\r\n",
      "ID_LIKE=debian\r\n",
      "PRETTY_NAME=\"Ubuntu 14.04.5 LTS\"\r\n",
      "VERSION_ID=\"14.04\"\r\n",
      "HOME_URL=\"http://www.ubuntu.com/\"\r\n",
      "SUPPORT_URL=\"http://help.ubuntu.com/\"\r\n",
      "BUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\r\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2016 NVIDIA Corporation\r\n",
      "Built on Tue_Jan_10_13:22:03_CST_2017\r\n",
      "Cuda compilation tools, release 8.0, V8.0.61\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 10 17:21:34 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GRID K520           Off  | 00000000:00:03.0 Off |                  N/A |\n",
      "| N/A   42C    P0    40W / 125W |      0MiB /  4036MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Load Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "Downloading data from https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(images_path, labels_path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig = load_mnist(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe62b292320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOcXwEzn1/1RGfWsx98xOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG Like Model With Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-22801ec20fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m ])\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;31m# input shape and dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                         raise ValueError('Cannot add an empty model '\n\u001b[0m\u001b[1;32m    442\u001b[0m                                          'to a `Sequential` model.')\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# In case of nested models: recover the first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outbound_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;31m# update self._inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0;31m# If the layer returns tensors from its inputs, unmodified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# we copy them to avoid loss of tensor metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;34m'kernel_constraint'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;34m'bias_constraint'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         }\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0mbase_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2963\u001b[0;31m     \u001b[0;31m# Returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2964\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2965\u001b[0m     \"\"\"\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "vgg_cnn = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28, 1)),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),    \n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_cnn.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "vgg_cnn.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_cnn.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_cnn.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = vgg_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg_cnn.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50, \n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "timeit=t1-t0\n",
    "timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# write out resutls\n",
    " \n",
    "#make confusion matrix plot\n",
    "def plot_confusion_matrix(cm, target_names, path, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    " \n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    " \n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    " \n",
    "    title:        the text to display at the top of the matrix\n",
    " \n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    " \n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    " \n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    " \n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    " \n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    " \n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    " \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    " \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    " \n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    " \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    " \n",
    " \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.gcf().subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(path + 'ConfMatx.png', format='png')\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = vgg_cnn.evaluate(X_test, y_test)\n",
    "predictions = vgg_cnn.predict(X_test)\n",
    "preds_index = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import metrics\n",
    "plot_confusion_matrix(cm           = metrics.confusion_matrix(y_test, preds_index), \n",
    "                      normalize    = False,\n",
    "                      path         = \"results/\",\n",
    "                      target_names = class_names,\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dominostats.json', 'w') as f:\n",
    "    f.write(json.dumps({\"Time\": round(timeit, 3), \"Acc\": round(test_acc, 3)}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
